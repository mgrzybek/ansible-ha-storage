---

- name: Get resources list
  shell: pcs config
  register: pcs_config
  run_once: true

# Cluster stuff
- name: Set clvm and dlm resources
  run_once: true
  when:
    - ha_storage_fs | lower != 'zfs'
    - ha_storage_use_clvm == true
    - pcs_config.stdout.find('g-clvm') < 0
  shell: >
    pcs resource create dlm controld \
        op monitor interval="60s" timeout="60s" \
        clone interleave=true ordered=true clone-max={{ ha_storage_cluster_nodes.stdout }} \
        --group g-clvm \
        --disabled && \
    pcs resource create clvm clvmd \
        op monitor interval="60s" timeout="60s" \
        --group g-clvm \
        --after dlm \
        --disabled && \
    pcs constraint location g-clvm rule \
        "{{ ha_storage_cluster_attribute_name }}" eq "{{ ha_storage_cluster_attribute_value }}" && \
    pcs resource enable g-clvm

#- name: Set ocfs2 resource
#  shell: crm script run cloned_o2cb
#  run_once: true
#  #when: '"ocfs2" in ha_storage.filesystems|json_query("fstype")'
#  when:  ha_storage_fs | lower == 'ocfs2'

# TODO: Set aliases in multipath.conf

######################################
# Deploy storage

# Openstack cinder devices
- name: Openstack Cinder resources
  run_once: true
  when:
    - ha_storage.cinder_volumes is defined
    - ha_storage.openrc is defined
    - pcs_config.stdout.find('g-' + ha_storage.volume_group) < 0
  block:
    - name: Openstack Cinder resources (multi-volumes)
      shell: >
        {% if ha_storage.cinder_volumes | length > 1 %}
            pcs resource create {{ ha_storage.volume_group }}-cinder ocf:heartbeat:openstack-cinder-volume \
                volume_ids={{ ha_storage.cinder_volumes | map('quote') | join(',') }} \
                minimum_volumes_number={{ ha_storage.cinder_volumes | length - 1 }} \
        {% else %}
            pcs resource create {{ ha_storage.volume_group }}-cinder openstack-cinder-volume \
                volume_id={{ ha_storage.cinder_volumes[0] }} \
        {% endif %}
                openrc={{ ha_storage.openrc }} \
                --group g-{{ ha_storage.volume_group }} \
                --disabled && \
            pcs constraint location g-{{ ha_storage.volume_group }} rule \
                score=-INFINITY  \
                "{{ ha_storage_cluster_attribute_name }}" ne "{{ ha_storage_cluster_attribute_value }}" && \
            pcs constraint location g-{{ ha_storage.volume_group }} rule \
                score=-INFINITY \
                not_defined openstack_id && \
            pcs constraint order \
                start {{ ha_storage_openstack_cloud_info_resource }} \
                then g-{{ ha_storage.volume_group }} && \
            pcs resource enable {{ ha_storage.volume_group }}-cinder

    - name: Sleep for 60 seconds and continue with play
      wait_for: timeout=60
      delegate_to: localhost
      become: false

- name: Wait for the Cinder resource to be running
  register: cinder_location
  until: cinder_location.stdout.find('is running on') > -1
  retries: 6
  delay: 10
  run_once: true
  shell: >
    crm_resource --locate --resource {{ ha_storage.volume_group }}-cinder \
        || exit 0

#
# 1. a. pvcreate
#    b. vgcreate
#
#

- name: Physical volume group building
  when:
    - not ha_storage.cinder_volumes is defined
    - not ha_storage.openrc is defined
  block:
    - name: Check luns availability
      shell: fdisk -l {{ ha_storage|json_query("luns[*].id")|join(" ") }} || exit 0
      register: fdisk_luns_result

    - when: fdisk_luns_result.stderr_lines | length == 0
      set_fact:
        create_datasets: true

    - when:
        - fdisk_luns_result.stderr_lines | length == 0
      block:
        - name: VG create
          when:
            - ha_storage_fs | lower != 'zfs'
          lvg:
            vg: "{{ ha_storage.volume_group }}"
            pvs: "{{ ha_storage|json_query('luns[*].id')|join(',') }}"
            vg_options: "{{ vg_options }}"

        - name: zpool create
          when:
            - ha_storage_fs | lower == 'zfs'
          shell: >
            crm_resource --locate --resource {{ ha_storage.volume_group }}_z || \
            zpool create -R {{ ha_storage_zpool_mountpoint }} \
                {{ ha_storage.volume_group }} \
                raidz1 \
                {{ ha_storage|json_query("luns[*].id")|join(" ") }}

- name: Cinder volume group building
  when:
    - ha_storage.cinder_volumes is defined
    - ha_storage.openrc is defined
  block:
    - name: Locate the cinder volume
      shell: crm_resource --locate --resource {{ ha_storage.volume_group }}-cinder | awk '{print $NF}'
      register: crm_resource_locate_cinder
      run_once: true

    - name: Check if LVM physical volume already exists
      shell: pvs
      register: pvs_result
      when:
        - ha_storage_fs | lower != 'zfs'

    # The device id is generated using the last 20 characters of the cinder id
    # We build a comma-separated list of devices
    - set_fact:
        temp_virtio_id_devices: "{% for id in ha_storage.cinder_volumes %}/dev/disk/by-id/virtio-{{ id[:20] }},{% endfor %}"

    # We clean the last comma of the list
    - set_fact:
        virtio_id_devices: "{{ temp_virtio_id_devices[:-1] }}"

    - name: Check volumes availability
      shell: fdisk -l {{ virtio_id_devices | regex_replace(',', ' ') }} || exit 0
      register: fdisk_cinder_result

    - when: fdisk_cinder_result.stderr_lines | length == 0
      set_fact:
        create_datasets: true

    - when:
        - crm_resource_locate_cinder.stdout.find(ansible_hostname) > -1
        - create_datasets | lower == 'true'
      block:
        - name: VG create
          when:
            - ha_storage_fs | lower != 'zfs'
            - pvs_result.stdout.find(ha_storage.volume_group) < 0
          lvg:
            vg: "{{ ha_storage.volume_group }}"
            pvs: "{{ virtio_id_devices }}"
            vg_options: "{{ vg_options }}"

        - name: zpool create
          when:
            - ha_storage_fs | lower == 'zfs'
          shell: >
            crm_resource --locate --resource {{ ha_storage.volume_group }}_z || \
            zpool create -R {{ ha_storage_zpool_mountpoint }} \
                {{ ha_storage.volume_group }} \
                raidz1 \
                {{ virtio_id_devices | regex_replace(',', ' ') }}

#
# 2. a. resource group
#
- name: Create resource group (LVM)
  run_once: true
  when:
    - ha_storage_fs | lower != 'zfs'
    - pcs_config.stdout.find(ha_storage.volume_group + '-vg') < 0
  block:
    - name: Create resource {{ ha_storage.volume_group }}-vg
      command: >
        pcs resource create {{ ha_storage.volume_group }}-vg LVM \
            volgrpname={{ ha_storage.volume_group }} \
            op monitor timeout=30 interval=10 \
            --group g-{{ ha_storage.volume_group }} \
            --disabled

    - when:
        - not ha_storage.cinder_volumes is defined
      block:
        - name: Add constraint ({{ ha_storage_cluster_attribute_name }} == {{ ha_storage_cluster_attribute_value }})
          when:
          command: >
            pcs constraint location g-{{ ha_storage.volume_group }} \
                rule \
                    "{{ ha_storage_cluster_attribute_name }}" \
                    eq \
                    "{{ ha_storage_cluster_attribute_value }}"

        - name: Add constraint (openstack_id is defined)
          command: >
            pcs constraint location g-{{ ha_storage.volume_group }} \
                rule \
                    defined openstack_id

- name: Create resource group (ZFS)
  run_once: true
  when:
    - ha_storage_fs | lower == 'zfs'
    - pcs_config.stdout.find(ha_storage.volume_group + '_z') < 0
  block:
    - name: Create resource {{ ha_storage.volume_group }}_z
      command: >
        pcs resource create {{ ha_storage.volume_group }}_z ZFS \
            pool={{ ha_storage.volume_group }} \
            op monitor timeout="30s" interval="10s" \
            op start timeout="30s" interval="0" \
            op stop timeout="30s" interval="0" \
            --disabled \
            --group g-{{ ha_storage.volume_group }}

    - name: Add constraint
      when:
        - not ha_storage.cinder_volumes is defined
      command: >
        pcs constraint location g-{{ ha_storage.volume_group }} \
            rule \
                "{{ ha_storage_cluster_attribute_name }}" \
                eq \
                "{{ ha_storage_cluster_attribute_value }}"

    - name: Enable {{ ha_storage.volume_group }}_z
      command: >
        pcs resource enable {{ ha_storage.volume_group }}_z

- name: Locate the resource group
  shell: crm_resource --resource g-{{ ha_storage.volume_group }} --locate
  register: crm_resource_locate_group
  until: crm_resource_locate_group.stdout.find("NOT running") < 0
  retries: 5
  delay: 10

#
# sfex stuff
# not available on centos / rhel yet
#
- name: sfex configuration
  when:
    - ha_storage_use_sfex == true
    - ha_storage.cinder_volumes | length == 1
    - crm_resource_locate_group.stdout.find(ansible_hostname) > -1
    - pcs_config.stdout.find(ha_storage.volume_group + "sfex") < 0
    - ansible_os_family | lower != 'redhat'
  block:
    - name: Enable sfex daemon
      when: pcs_config.stdout.find('sfex-clone') < 0
      shell: >
        pcs resource create sfex sfex \
            op monitor timeout="30s" interval="10s" \
            op start timeout="30s" interval="0" \
            op stop timeout="30s" interval="0" \
            --disabled \
            --clone && \
        pcs constraint location  rule \
            "{{ ha_storage_cluster_attribute_name }}" eq "{{ ha_storage_cluster_attribute_value }}" && \
        pcs resource enable sfex

    - name: Create sfex volume
      lvol: vg={{ ha_storage.volume_group }} lv=sfex size=10M
      when:
        - ha_storage_fs | lower != 'zfs'

    - name: Create sfex volume
      shell: >
        zfs list | grep -q {{ ha_storage.volume_group }}/sfex || \
        zfs create "{{ ha_storage.volume_group }}/sfex" -o mountpoint=none
      when:
        - ha_storage_fs | lower == 'zfs'

    - name: Wait for the sfex resource to be running
      shell: >
        crm_resource --locate --resource sfex-clone \
            || exit 0
      register: cinder_location
      until: cinder_location.stdout.find('is running on') > -1
      retries: 6
      delay: 10

    - name: Configure sfex partition
      command: sfex_init /dev/{{ ha_storage.volume_group }}/sfex

    - name: Add sfex resource
      shell: >
        pcs resource create {{ ha_storage.volume_group }}-sfex \
            device="/dev/{{ ha_storage.volume_group }}/sfex" \
            collision_timeout=1 \
            monitor_interval=1 \
            op monitor timeout="30s" interval="10s" \
            op start timeout="30s" interval="0" \
            op stop timeout="30s" interval="0" \
            --group g-{{ ha_storage.volume_group }} \
            --after {{ ha_storage.volume_group }}-cinder

# 3. a. lvcreate
#    b. add resource to group
#    c. mkfs

#- name: Freeze the VG location
#  command: pcs resource move g-{{ ha_storage.volume_group }} {{ ansible_hostname }}
#  when: crm_resource_locate_group.stdout.find(ansible_hostname) > -1

- name: Create the datasets
  when:
    - ha_storage.filesystems is defined
    - ha_storage.filesystems | length > 0
  block:
    - when:
        - ha_storage_fs | lower != 'zfs'
      block:
        - include_tasks: ../ha-storage_post_install_postmounts.yml

        - include_tasks: ha-storage_post_install_lvm_volume.yml
          with_items: "{{ ha_storage.filesystems }}"
          when:
            - crm_resource_locate_group.stdout.find(ansible_hostname) > -1

    - when:
        - ha_storage_fs | lower == 'zfs'
        - crm_resource_locate_group.stdout.find(ansible_hostname) > -1
      include_tasks: ha-storage_post_install_zfs_dataset.yml
      with_items: "{{ ha_storage.filesystems }}"

# Services
- name: Add the appending resources
  run_once: true
  when:
    - ha_storage.append_resources is defined
    - ha_storage.append_resources | length > 0
  block:
    - name: Get group configuration
      command: pcs resource show g-{{ ha_storage.volume_group }}
      register: pcs_resource_show

    - name: Create the resource to append
      when: pcs_resource_show.stdout.find(item.name + " (") < 0
      with_items: "{{ ha_storage.append_resources }}"
      shell: >
        pcs resource create {{ item.name }} {{ item.type }} \
            {% for param in item.params %}
                {{ param }} \
            {% endfor %}
            {% for op in item.op %}
                op {{ op }} \
            {% endfor %}
            --group g-{{ ha_storage.volume_group }}

- name: Enable the VG resource
  run_once: true
  command: pcs resource enable {{ ha_storage.volume_group }}-vg
  when: ha_storage_fs | lower != 'zfs'
